{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logical Explanation for Below Code:\n"
      ],
      "metadata": {
        "id": "Mz3k8bhncgjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read the data from an Excel file containing college reviews.\n",
        "\n",
        "2. Define functions to:\n",
        "   - Determine the sentiment of a text.\n",
        "   - Perform topic modeling on a collection of texts.\n",
        "   - Summarize reviews for a given college.\n",
        "\n",
        "3. Assign sentiment to each review by applying the sentiment analysis function to the 'Review' column.\n",
        "\n",
        "4. Assign a topic to each review by performing topic modeling using the 'Review' column.\n",
        "\n",
        "5. Create a summary table for each college by:\n",
        "   - Extracting unique college names.\n",
        "   - For each college, concatenate all reviews into a single summary.\n",
        "\n",
        "6. Save the results to a new Excel file with two sheets:\n",
        "   - 'Review_Data_with_Sentiment_and_Topic': Contains the original data with sentiment and topic columns.\n",
        "   - 'Review_Summary': Contains the summary of reviews for each college.\n"
      ],
      "metadata": {
        "id": "T1zFV2q1awQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "D9JN19jXHBE1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the Excel file\n",
        "df = pd.read_excel(\"/content/Sample_Interview.xlsx\")"
      ],
      "metadata": {
        "id": "KD7ntAZKXJ_e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine sentiment\n",
        "def get_sentiment(text):\n",
        "    \"\"\"\n",
        "    Determine the sentiment of a given text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The text for which sentiment needs to be determined.\n",
        "\n",
        "    Returns:\n",
        "    str: The sentiment of the text ('Positive', 'Neutral', or 'Negative').\n",
        "    \"\"\"\n",
        "    # Create a TextBlob object from the input 'text'\n",
        "    analysis = TextBlob(text)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif analysis.sentiment.polarity == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Negative'\n",
        "\n"
      ],
      "metadata": {
        "id": "Ks-lVkItXVhH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform topic modeling\n",
        "def get_topics(texts):\n",
        "    \"\"\"\n",
        "    Perform topic modeling on a collection of texts.\n",
        "\n",
        "    Parameters:\n",
        "    texts (list of str): A list of texts to be analyzed.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the vectorizer and the LDA model.\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "    tf = vectorizer.fit_transform(texts)\n",
        "    lda_model = LatentDirichletAllocation(n_components=2, random_state=42)\n",
        "    lda_model.fit(tf)\n",
        "    return vectorizer, lda_model\n"
      ],
      "metadata": {
        "id": "t2rsDHjDXgSX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to summarize reviews for each college\n",
        "def summarize_reviews(college_name):\n",
        "    \"\"\"\n",
        "    Summarize reviews for a given college.\n",
        "\n",
        "    Parameters:\n",
        "    college_name (str): The name of the college for which reviews need to be summarized.\n",
        "\n",
        "    Returns:\n",
        "    str: The summary of reviews for the given college.\n",
        "    \"\"\"\n",
        "    reviews = df[df['college_name'] == college_name]['Review']\n",
        "    summary = ' '.join(reviews)\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "rx0A3mlqXp9O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign sentiment to each review\n",
        "df['polarity'] = df['Review'].apply(get_sentiment)\n"
      ],
      "metadata": {
        "id": "Si-VfE2yX3ya"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign topic to each review\n",
        "vectorizer, topics_model = get_topics(df['Review'])\n",
        "df['topic'] = topics_model.transform(vectorizer.transform(df['Review'])).argmax(axis=1)\n"
      ],
      "metadata": {
        "id": "jfVRIn99XjM-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a summary table for each college\n",
        "colleges = df['college_name'].unique()\n",
        "summary_data = {'college': [], 'summary': []}\n",
        "for college in colleges:\n",
        "    summary_data['college'].append(college)\n",
        "    summary_data['summary'].append(summarize_reviews(college))\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n"
      ],
      "metadata": {
        "id": "Bq7SLMRZXvVX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results to a new Excel file\n",
        "with pd.ExcelWriter('review_analysis_results.xlsx') as writer:\n",
        "    df.to_excel(writer, sheet_name='Review_Data_with_Sentiment_and_Topic', index=False)\n",
        "    summary_df.to_excel(writer, sheet_name='Review_Summary', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbwg1a6sHD9N",
        "outputId": "a0826466-ba40-4b48-e764-a39efc1a3a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
            "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
          ]
        }
      ]
    }
  ]
}